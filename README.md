# Multi-Armed Bandits
This repository contains a notebook that visualizes different Multi-Armed Bandit algorithms in the context of online advertising. You can play a game and manually optimize a virtual campaign. Your results are compared to the different MAB algorithms. 
